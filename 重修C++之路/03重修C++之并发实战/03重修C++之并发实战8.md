# 03重修C++之并发实战 8

【设计并发代码】

## 8.1 在线程间划分工作的技术



### 8.1.1 处理开始前在线程间划分数据

划分数据最简单的方法就是将第一之组N个元素分配给一个线程，将下一组N个元素分配给另一个线程，以此类推，但是也可以使用别的模式。无论如何划分数据，每个线程只能处理分配给它的元素，并且直到它完成任务的时候才能与别的线程通信。这种结构与使用消息传递接口（Message Passing Intrerface, MPI）或者OpenMP框架编程的结构是类似的。



### 8.1.2 递归地划分数据

快速排序算法有两个基本步骤，基于其中一个元素（关键值）将数据划分为两部分，一部分在关键值之前，一部分在关键值之后，然后递归地排序这两部分。我们无法通过预先划分数据来实行并行，因为只有当处理元素的时候才知道这个元素是属于那一部分的，如果打算并行这个算法就需要把握递归的本质。每次递归的时候，会调用更多的quick_sort函数来排序关键点之前和关键点之后的元素。这些递归调用是完全独立的，因为它们读取完全不同的集合。

当对大规模的数据进行排序的时候，为每一个递归调用生成一个新线程会很快产生大量线程。在考虑性能的时候，就很快就会使线程数量达到上限。这里对任务进行划分只需要严格控制线程数量，我们只需要将此块存储到线程安全栈中，而不是递归调用创建一个薪线程。如果线程不在工作，就说明它已经处理完所有的块，或等待存储在栈中的块。此时可以从栈中得到一个块并将它排序。书里给出了使用待排序块的并行快速排序代码如下：



```cpp
#include <iostream>
#include <algorithm>
#include <stack>
#include <list>
#include <vector>
#include <future>
#include <chrono>

#include "threadsafe_stack.h"

template<typename T>
class chunk_to_sort
{
public:
    std::list<T> data;
    std::promise<std::list<T> > promise;

    chunk_to_sort() {}
    chunk_to_sort(const chunk_to_sort &other)
    {
        data = other.data;
    }

};

template<typename T>
class sorter
{
private:
    threadsafe_stack<chunk_to_sort<T>> chunks;
    std::vector<std::thread> threads;
    unsigned const max_thread_count;
    std::atomic<bool> end_of_data;

public:
    sorter() :
        max_thread_count(std::thread::hardware_concurrency() - 1),
        end_of_data(false)
    {}
    ~sorter()
    {
        end_of_data = true;
        for (unsigned i = 0; i < threads.size(); ++i)
        {
            threads[i].join();
        }
    }
    void try_sort_chunk()
    {
        if (chunks.empty()) 
            return;
        std::shared_ptr<chunk_to_sort<T> > chunk = chunks.pop();
        if (chunk)
        {
            sort_chunk(chunk);
        }
    }
    std::list<T> do_sort(std::list<T>& chunk_data)
    {
        if (chunk_data.empty())
        {
            return chunk_data;
        }
        std::list<T> result;
        // 将chunk_data中第一个元素取出放入result
        result.splice(result.begin(), chunk_data, chunk_data.begin());
        // 将该元素值作为base值
        T const& partition_val = *result.begin();
        
        // 将chunk_data中剩余元素根据base值分区
        typename std::list<T>::iterator divide_point =
            std::partition(chunk_data.begin(), chunk_data.end(),
                [&](T const& val) {return val < partition_val; });
        // 小于base值的部分保存至new_lower_chunk，splice之后的chunk_data即为大于base值的部分
        chunk_to_sort<T> new_lower_chunk;
        new_lower_chunk.data.splice(new_lower_chunk.data.end(),
            chunk_data, chunk_data.begin(),
            divide_point);
        // 小于base部分的list压入全局类型栈
        std::future<std::list<T> > new_lower =
            new_lower_chunk.promise.get_future();
        chunks.push(std::move(new_lower_chunk));
        // 线程数组添加线程 ？？如果超过最大线程数会怎样？？
        if (threads.size() < max_thread_count)
        {
            threads.push_back(std::thread(&sorter<T>::sort_thread, this));

        }

        // 大于base值的部分递归调用自身，继续进行分区排序
        std::list<T> new_higher(do_sort(chunk_data));
        // 将排好序的大于base部分的list拼接到result
        result.splice(result.end(), new_higher);
        // 小于base部分的list如果未完成则调用try_sort_chunk
        while (new_lower.wait_for(std::chrono::seconds(0)) !=
            std::future_status::ready)
        {
            try_sort_chunk();
        }
        // 将排好序的小于base部分list拼接到result，形成完整排好序的list
        result.splice(result.begin(), new_lower.get());
        // 返回结果
        return result;
    }
    void sort_chunk(std::shared_ptr<chunk_to_sort<T> > const& chunk)
    {
        chunk->promise.set_value(do_sort(chunk->data));
    }
    void sort_thread()
    {
        while (!end_of_data)
        {
            try_sort_chunk();
            std::this_thread::yield();
        }
    }
};
 
template<typename T>
std::list<T> parallel_quick_sort(std::list<T> input) //代表了sorter类的大部分功能
{
    if (input.empty())
    {
        return input;
    }
    sorter<T> s;
    return s.do_sort(input);
}

/** 测试 **/
int main(int argc, char const *argv[])
{
    auto print = [](const int& n) {std::cout << " " << n; };
    std::list<int> table = {52, 63, 8, -3, 0, 999, 66, 128, -60};
    std::for_each(table.begin(), table.end(), print);
    std::cout << std::endl;

    std::list<int> res = parallel_quick_sort(table);

    

    std::for_each(res.begin(), res.end(), print);
    std::cout << std::endl;

    return 0;
}
// 测试部分出现了问题如下：
/**
 * 1.不修改chunk_to_sort类时（原文用的struct）编译时会发生报错，
 *   报错内容为调用可不存在的赋值构造函数；
 * 2.修改后出现抛出空栈异常的，程序出现段错误。。。本人功力不够，多线程gdb调试不明白；
 * 3.初步判断可能原因有以下几点：
 *    -因为在线程池中有可能存在无限制的递归调用
 *    -如果 chunks 为空，则该函数将不断轮询 chunks 直到其非空，这可能会导致 CPU 占用过高。
 */
```

最近刚从新捡起来c++，需要熟悉一段时间，而且多线程这里本身也是刚学的所以不太熟悉，这个问题先放这里，回头再复习的时候再研究。这段大概的思想是先使用原来的递归方法，不过在划分区域时不断将小于目标值的部分压入线程安全栈中，大于目标值的部分递归调用，然后对栈里的片段也快排（这里看的我有点晕了，猪脑过载了），不过我看代码大概的原理是“优先”小的排序不断将返回的小的值插到结果list的最前边，最后形成一个递增序列，但是不知道代码哪里有问题。。。



## 8.2 影响并发代码性能的因素

 ### 8.2.1 处理器数量

处理器数量和结构是多线程程序的首要和关键的因素。可能会出现**过度订阅**的问题，为了线程数量能跟随硬件数量扩展，C++11提供了`std::thread::hardware_concurrency()` 方法查看当前硬件的线程支持情况，当然这个函数并没有考虑其他运行的程序所以在使用是仍然需要考虑具体情况。

### 8.2.2 数据竞争和兵乓缓存

一个处理器已经准备好更新这个值，但是另一个处理器已经在做了，这就要等待另一个处理器更新，并且这个改动已经传播完成，这种情况被称为**高竞争（high contention）**。如果处理器很少需要相互等待，则称为**低竞争（low contention）**。在这样的环境中，这个值在各个处理器的缓存中来回传递，这被称为**乒乓缓存（cache ping-pong）**，而且还会严重影响程序的性能。为了避免这种情况，可以依赖于提高并发度，尽可能地避免两个线程竞争从一个内存位置。不过这并不容易做到，即便一个特定内存区域只有一个线程会去访问，依然会遇到乒乓缓存，因为存在**假共享（false sharing）**地问题。



### 8.2.3 假共享

处理器缓存的最小单位通常不是一个内存地址，而是一块称为**缓存线（cache line）**的内存。这些内存块一般大小为32~64字节，取决于具体的处理器。缓存只能处理缓存线大小的内存块，相邻地址的数据会被载入同一个缓存线。有时候这是好事，线程访问的数据在同一个缓存线比分布在多个缓存线更高。但是如果缓存线内有不相关但需要别的线程访问的数据，会导致严重的性能问题。假设你有一个int型数组以及一组线程，每个线程都不停访问和改写数组中彼此正交的部分。因为int小于缓存线，多个元素在一个缓存线，这样即使线程只访问自己的数据，仍然有乒乓缓存。一个线程在更改其访问的数据时，缓存线的所有权需要转移到其所在处理器，而另一个线程所需的数据可能也在这个缓存线上，当它访问时又要转移。这个缓存线是共享的，但是数据不共享，因此被称为假共享。



### 8.2.4 数据应该多紧密

假共享是由于一个线程访问的数据与另一个线程靠的太近，而另一个与数据布局直接相关的性能隐患则来自一个线程本身。根源是数据的相邻度。如果线程访问的数据分散在内存中，意味着这些数据分布在各个缓存上。因此，更多的缓存线需要加载到处理器的缓存中，这会增加内存访问延迟，性能要低于数据分布紧密的情况。

同时，这也会增加线程需要的某个缓存线同时含有其他线程访问的数据的可能性。在极端情况下，缓存中无关数据会多于你关心的数据。这会浪费宝贵的缓存空间，迫使处理器将需要的数据移除缓存来腾出空间，这样更容易缓存未命中而不得不从内存中获取数据。

这对单线程代码性能很重要，而我们在这里考虑它的原因是**任务切换（task switching）**。如果有多余的CPU核心数量的线程，每个核心都将运行多个线程。这这会增加缓存的压力。因为需要保证不同线程访问不同的缓存线以避免假共享。因此，当处理器切换线程时，数据分散在多个缓存线比每个线程的数据都紧靠在同一个缓存线，更可能需要重载这些缓存线。任务切换导致的问题在大量线程处于就绪而不是等待状态时特别突出。



## 8.3 为多线程性能设计数据结构

当为多线程性能设计你都数据结构时需要考虑的关键问题是竞争、假共享以及数据接近。这三个方面都会对性能产生很大影响，并且通常你可以通过改变数据布局或者改变分配给某线程的数据元素来提高性能。

测试假共享是否是一个问题的方法就是在数据元素间增加可以被不同线程并发读取的大块填充数据，例如：

```cpp
struct protected_data
{
    std::mutex m;
    char padding[65536]; //65536字节是为了显著大于缓存线
    my_data data_to_protect;
}
// 来测试互斥元竞争问题或使用：
struct my_data
{
    data_item1 d1;
    data_item2 d2;
    char padding[65536];
};
my_data some_array[256];
```

来测试数组数据是否假共享。如果这样做提高了性能，就可以得知假共享确实是一个问题，并且你可以保留填充数据或者通过重新安排数据读取方式来消除假共享。



## 8.4 为并发设计时的额外考虑



### 8.4.1 并行算法中的异常安全

==记得看C++的书说过虽然C++有异常机制，但是C++不提倡使用异常抛出。。。==



### 8.4.2可扩展性和阿姆达尔定律

**可扩展性**是关于确保你的应用可以利用系统中增加的处理器。

一种简单的方法就是将程序划分为只有一个线程在做有用的工作“串行的”部分和所有可以获得处理器都在做有用工作的部分“并行的”部分，因为可以在更多的处理器间划分工作，但是“串行的”部分仍然是串行的。在这样一种简单假设下，你就可以通过增加处理器数量来估计可以获得的性能。如果“连续的”部分组成程序的一个部分$f_s$，那么使用$N$个处理器获得的性能$P$就可以估计为：$$ P=\frac{1}{f_s+\frac{1-f_s}{N} } $$ ，这就是**阿姆达尔定律（Amdale's law）**。



## 8.5 在实践中设计并发代码

### 8.5.1 std::for_each的并行设计 

















